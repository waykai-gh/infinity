# Документация настроек проекта XOR для продакшн, локального запуска

## Обзор проекта

Сервис располагается на выделенном сервере mySrv, где хостится телеграм бот (@infinityXorAi_bot) и бэкенд часть. К директориям проекта относятся: `ai-service-backend/` и `xor-bot` - в них располагается код проекта.  Телеграм бот используется отдельный от основного со своим отдельным токеном и для запуска требует `BOT_XOR_TOKEN` и `AI_BASE_URL`. 

## Telegram бот XOR

### Описание

Команда бота `/start` выдает шаблонное приветствие.

Далее бот слушает весь текст и пересылает его в `POST {AI_BASE_URL}/api/llm`, передавая `prompt`. Пользователь на этом этапе должен получать ответ (`response`) от нейросети. В случае ошибки пользователю приходит соответствующее сообщение, ошибки логируются.

### Дополнительные файлы

- `src/ai-files/xor.ts` — отдельный обработчик для тестового эндпоинта `/api/xor-predict`
- `src/ai-files/aiMainCommands.ts` — заготовка callback-команды
- `Dockerfile`: идентичен `bot/` (dev-режим внутри контейнера)

### Переменные окружения

- `BOT_XOR_TOKEN` — токен Telegram бота
- `AI_BASE_URL` — обычно `http://ai-service-backend:3000` внутри docker-сети

## AI-сервис

**Расположение:** `backend/ai-service-backend/`

### Назначение

Единая точка для запросов к локальной Ollama и маленькой нейросети XOR.

### Скрипты

- `npm run build` → `tsc`
- `npm start` → `node dist/index.js`

Dockerfile билдит и запускает прод-режим на Node 20.

### Переменные окружения

- `OLLAMA_BASE_URL` (например, `http://ollama:11434` в Compose или `http://host.docker.internal:11434` локально)
- `OLLAMA_MODEL` (по умолчанию Qwen/Gemma; управляет моделью генерации)

### API эндпоинты

- `GET /health/ollama` — проверяет `OLLAMA_BASE_URL/api/tags`; возвращает `{ok: true, models:[...]}` либо 503
- `POST /api/llm` — проксирует `prompt` (и опционально `model`, `options`) в Ollama `/api/generate` со `stream: false`; выдаёт JSON `{ model, response }` или ошибки `ollama_bad_gateway` / `ollama_unavailable`
- `POST /api/xor-predict` — использует заранее обученную SimpleNN (2 входа, 4 скрытых, 1 выход) для XOR; ожидает `x: [number, number]`, возвращает `{result}`

### Код нейросети

`src/neuralNetwork.ts` содержит реализацию полносвязной сети с сигмоидой, backprop и SGD; при старте тренирует на стандартных XOR-данных (5000 эпох, lr=0.8).

### HTTP-клиент

Используется глобальный `fetch` Node 20 (import не нужен). Обработка ошибок минимальна, таймауты не заданы.

## Деплой

### Продакшн

Для продакшн запуска нужно выполнить подключение к mySrv, перейти в папку проекта и ввести:

```bash
docker-compose up -d
```

Если в проект были внесены изменения, потребуется:

1. Сделать коммит с устройства, на котором были внесены изменения, на GitHub в ветку `main`
2. На удаленном сервере (mySrv) выполнить `git pull`, чтобы получить изменения с удаленного репозитория
3. Далее ввести команду `docker-compose up` для повторной сборки проекта и последующего запуска

### Разработка

Для полного dev запуска AI сервиса (также будет запущен и основной бот @NNfinity_bot) нужно перейти в папку проекта (`\infinity-project`) и ввести:

```bash
docker-compose up
```

Для запуска бота отдельно выполнить:

```bash
cd xor-bot
npm run dev
```

Для запуска отдельно бэкенда выполнить:

```bash
cd ai-service-backend
docker run <образ>
```

## Команды Docker

### Основные команды Docker для работы с контейнерами и образами

- `docker run <образ>` — запустить новый контейнер из образа (с флагом `-d` в фоне)
- `docker ps` — показать запущенные контейнеры
- `docker ps -a` — показать все контейнеры (в том числе остановленные)
- `docker stop <контейнер>` — остановить контейнер
- `docker start <контейнер>` — запустить остановленный контейнер
- `docker exec -it <контейнер> bash` — войти в работающий контейнер через терминал
- `docker logs <контейнер>` — посмотреть логи контейнера
- `docker rm <контейнер>` — удалить контейнер
- `docker images` — показать локальные образы
- `docker rmi <образ>` — удалить образ

### Основные команды Docker Compose для управления многоконтейнерными приложениями

- `docker-compose up` — собрать и запустить все сервисы, описанные в файле `docker-compose.yml` (без флага запускается в интерактивном режиме)
- `docker-compose up -d` — запустить сервисы в фоне
- `docker-compose down` — остановить и удалить контейнеры, сети и тома, созданные compose
- `docker-compose stop` — остановить контейнеры без удаления
- `docker-compose restart` — перезапустить контейнеры
- `docker-compose build` — пересобрать образы для сервисов
- `docker-compose pull` — скачать образы, указанные в compose файле
- `docker-compose logs` — посмотреть логи всех или конкретного сервиса
- `docker-compose ps` — показать состояние контейнеров в проекте
- `docker-compose exec <сервис> <команда>` — выполнить команду внутри контейнера сервиса

## Команды Git

### Инициализация и клонирование

**Инициализация репозитория (при необходимости):**

```bash
git init
```

**Клонирование удалённого репозитория:**

```bash
git clone <URL репозитория>
```

### Работа с файлами

**Проверка статуса файлов:**

```bash
git status
```

**Добавление файлов в индекс для коммита:**

```bash
git add <файл или . для всех файлов>
```

**Создание коммита с сообщением:**

```bash
git commit -m "Сообщение коммита"
```

### Работа с ветками

- `git branch` — список веток
- `git branch <название>` — создание новой ветки
- `git checkout <ветка>` — переключение на ветку
- `git merge <ветка>` — слияние ветки в текущую

### Синхронизация с удалённым репозиторием

**Отправка изменений в удалённый репозиторий:**

```bash
git push
```

(первая отправка может быть `git push -u origin <ветка>`)

**Получение обновлений с удалённого репозитория:**

```bash
git pull
```
